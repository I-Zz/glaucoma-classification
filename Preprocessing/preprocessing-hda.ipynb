{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c79d7ef5",
   "metadata": {
    "papermill": {
     "duration": 0.00417,
     "end_time": "2024-10-25T17:54:37.361000",
     "exception": false,
     "start_time": "2024-10-25T17:54:37.356830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CSV Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e0ff69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:37.371771Z",
     "iopub.status.busy": "2024-10-25T17:54:37.371325Z",
     "iopub.status.idle": "2024-10-25T17:54:40.285182Z",
     "shell.execute_reply": "2024-10-25T17:54:40.283888Z"
    },
    "papermill": {
     "duration": 2.92242,
     "end_time": "2024-10-25T17:54:40.287889",
     "exception": false,
     "start_time": "2024-10-25T17:54:37.365469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ef3d4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.298799Z",
     "iopub.status.busy": "2024-10-25T17:54:40.298226Z",
     "iopub.status.idle": "2024-10-25T17:54:40.303690Z",
     "shell.execute_reply": "2024-10-25T17:54:40.302503Z"
    },
    "papermill": {
     "duration": 0.013568,
     "end_time": "2024-10-25T17:54:40.305983",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.292415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/justraigs-with-paths/JustRAIGS_Train_labels_with_paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f953efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.317477Z",
     "iopub.status.busy": "2024-10-25T17:54:40.317048Z",
     "iopub.status.idle": "2024-10-25T17:54:40.322415Z",
     "shell.execute_reply": "2024-10-25T17:54:40.321007Z"
    },
    "papermill": {
     "duration": 0.014072,
     "end_time": "2024-10-25T17:54:40.324770",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.310698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_counts = df['Final Label'].value_counts().reset_index()\n",
    "print(label_counts)\n",
    "\n",
    "# Rename the columns to 'Label' and 'Count'\n",
    "label_counts.columns = ['Label', 'Count']\n",
    "\n",
    "# Create a bar plot using Seaborn\n",
    "sns.barplot(x='Label', y='Count', data=label_counts)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Final Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9808d489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.335866Z",
     "iopub.status.busy": "2024-10-25T17:54:40.335416Z",
     "iopub.status.idle": "2024-10-25T17:54:40.340712Z",
     "shell.execute_reply": "2024-10-25T17:54:40.339559Z"
    },
    "papermill": {
     "duration": 0.013639,
     "end_time": "2024-10-25T17:54:40.342998",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.329359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downsample_majority_class(df, rg_class='RG', nrg_class='NRG', ratio=1):\n",
    "    \"\"\"Downsample the majority class (NRG) to a given ratio compared to RG.\"\"\"\n",
    "    rg_df = df[df['Final Label'] == rg_class]\n",
    "    nrg_df = df[df['Final Label'] == nrg_class]\n",
    "\n",
    "    # Downsample NRG to match the desired ratio with RG\n",
    "    nrg_downsampled = nrg_df.sample(n=len(rg_df) * ratio, random_state=42)\n",
    "    \n",
    "    # Combine the downsampled NRG with RG\n",
    "    downsampled_df = pd.concat([rg_df, nrg_downsampled], ignore_index=True)\n",
    "    return downsampled_df\n",
    "\n",
    "# Example usage\n",
    "df_downsampled = downsample_majority_class(df, rg_class='RG', nrg_class='NRG', ratio=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2dc67",
   "metadata": {
    "papermill": {
     "duration": 0.004479,
     "end_time": "2024-10-25T17:54:40.352627",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.348148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dfa39ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.364563Z",
     "iopub.status.busy": "2024-10-25T17:54:40.363509Z",
     "iopub.status.idle": "2024-10-25T17:54:40.369317Z",
     "shell.execute_reply": "2024-10-25T17:54:40.367886Z"
    },
    "papermill": {
     "duration": 0.014441,
     "end_time": "2024-10-25T17:54:40.371843",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.357402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_counts = df_downsampled['Final Label'].value_counts().reset_index()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674806d2",
   "metadata": {
    "papermill": {
     "duration": 0.00431,
     "end_time": "2024-10-25T17:54:40.381761",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.377451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3daf8d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.393330Z",
     "iopub.status.busy": "2024-10-25T17:54:40.392811Z",
     "iopub.status.idle": "2024-10-25T17:54:40.401025Z",
     "shell.execute_reply": "2024-10-25T17:54:40.399730Z"
    },
    "papermill": {
     "duration": 0.017244,
     "end_time": "2024-10-25T17:54:40.403572",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.386328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "\n",
    "    df_temp = df_downsampled\n",
    "\n",
    "    # Filter and relabel the dataset\n",
    "    rg_instances = df_temp[df_temp['Final Label'] == 'RG']\n",
    "    rg_instances['Final Label'] = 1  # Setting RG class label to 1\n",
    "    rg_instances.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    nrg_instances = df_temp[df_temp['Final Label'] == 'NRG']\n",
    "    nrg_instances['Final Label'] = 0  # Setting NRG class label to 0\n",
    "    nrg_instances.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Split the dataset for classification\n",
    "    train_rg, test_rg = train_test_split(rg_instances[['Eye ID', 'Final Label', 'Image Path']],\n",
    "                                         test_size=0.1, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Split the data into training and testing datasets for glaucoma classification. \n",
    "    # The test set is balanced, containing 10% of all referable glaucoma cases \n",
    "    # along with an equal number of non-referable glaucoma cases.\n",
    "    train_nrg, test_nrg = train_test_split(nrg_instances[['Eye ID', 'Final Label', 'Image Path']],\n",
    "                                           test_size=len(test_rg), random_state=42, shuffle=True)\n",
    "    \n",
    "    # Merge RG and NRG for glaucoma classification\n",
    "    train_glaucoma = pd.concat([train_rg, train_nrg], ignore_index=True)\n",
    "    test_glaucoma = pd.concat([test_rg, test_nrg], ignore_index=True)\n",
    "\n",
    "    # Shuffle the data\n",
    "    train_rg = train_rg.sample(frac=1).reset_index(drop=True)\n",
    "    test_rg = test_rg.sample(frac=1).reset_index(drop=True)\n",
    "    train_glaucoma = train_glaucoma.sample(frac=1).reset_index(drop=True)\n",
    "    test_glaucoma = test_glaucoma.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Save to CSV (including image paths)\n",
    "    \n",
    "    train_glaucoma.to_csv('/kaggle/working/glaucoma_no_mask_train.csv', index=False)\n",
    "    test_glaucoma.to_csv('/kaggle/working/glaucoma_no_mask_tes.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e960008f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.415086Z",
     "iopub.status.busy": "2024-10-25T17:54:40.414654Z",
     "iopub.status.idle": "2024-10-25T17:54:40.420213Z",
     "shell.execute_reply": "2024-10-25T17:54:40.418761Z"
    },
    "papermill": {
     "duration": 0.014082,
     "end_time": "2024-10-25T17:54:40.422787",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.408705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = pd.read_csv('/kaggle/working/glaucoma_no_mask_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e7ebfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.474085Z",
     "iopub.status.busy": "2024-10-25T17:54:40.472644Z",
     "iopub.status.idle": "2024-10-25T17:54:40.479230Z",
     "shell.execute_reply": "2024-10-25T17:54:40.478070Z"
    },
    "papermill": {
     "duration": 0.01531,
     "end_time": "2024-10-25T17:54:40.481761",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.466451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'Username'\n",
    "os.environ['KAGGLE_KEY'] = 'API_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca690a",
   "metadata": {},
   "source": [
    "# Contrast Enhancement: CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b6e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T17:54:40.494058Z",
     "iopub.status.busy": "2024-10-25T17:54:40.493125Z",
     "iopub.status.idle": "2024-10-25T19:24:16.639032Z",
     "shell.execute_reply": "2024-10-25T19:24:16.636399Z"
    },
    "papermill": {
     "duration": 5376.155431,
     "end_time": "2024-10-25T19:24:16.642082",
     "exception": false,
     "start_time": "2024-10-25T17:54:40.486651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json \n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def apply_clahe(img, clip_limit=3.0, tile_grid_size=(8, 8)):\n",
    "    \"\"\"Applying CLAHE contrast enhancement on each color channel separately.\"\"\"\n",
    "    img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    r, g, b = cv2.split(img)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    r_clahe, g_clahe, b_clahe = clahe.apply(r), clahe.apply(g), clahe.apply(b)\n",
    "    clahe_img = cv2.merge([r_clahe, g_clahe, b_clahe])\n",
    "    return cv2.cvtColor(clahe_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def trim_and_resize(im, output_size):\n",
    "    \"\"\"Trims margins, maintains aspect ratio, and resizes to the specified output size.\"\"\"\n",
    "    percentage = 0.02\n",
    "    img = np.array(im)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    im_binary = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
    "    row_sums = np.sum(im_binary, axis=1)\n",
    "    col_sums = np.sum(im_binary, axis=0)\n",
    "    rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
    "    cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
    "    if rows.size and cols.size:\n",
    "        min_row, min_col = np.min(rows), np.min(cols)\n",
    "        max_row, max_col = np.max(rows), np.max(cols)\n",
    "        img = img[min_row:max_row+1, min_col:max_col+1]\n",
    "    im_pil = Image.fromarray(img)\n",
    "    old_size = im_pil.size\n",
    "    ratio = float(output_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    im_resized = im_pil.resize(new_size, Image.LANCZOS)\n",
    "    new_im = Image.new(\"RGB\", (output_size, output_size))\n",
    "    new_im.paste(im_resized, ((output_size - new_size[0]) // 2, (output_size - new_size[1]) // 2))\n",
    "    return new_im\n",
    "\n",
    "def process_and_save_images(image_paths, output_path_folder, output_size):\n",
    "    \"\"\"Processes a list of images and saves them to the output folder.\"\"\"\n",
    "    if not os.path.exists(output_path_folder):\n",
    "        os.makedirs(output_path_folder)\n",
    "    \n",
    "    for image_path in tqdm(image_paths):\n",
    "        img_file = os.path.basename(image_path)\n",
    "        output_image_path = os.path.join(output_path_folder, img_file)\n",
    "        if not os.path.exists(output_image_path):\n",
    "            try:\n",
    "                image_original = cv2.imread(image_path)\n",
    "                if image_original is not None:\n",
    "                    image_trimmed_resized = trim_and_resize(image_original, output_size)\n",
    "                    image_clahe = apply_clahe(image_trimmed_resized)\n",
    "                    cv2.imwrite(output_image_path, image_clahe)\n",
    "                    print(f\"Processed and saved: {output_image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping {output_image_path}, already exists.\")\n",
    "    return output_path_folder  # Return the directory path for later use\n",
    "\n",
    "def create_dataset(output_dir, dataset_title, dataset_id):\n",
    "    \"\"\"Creates a new dataset in Kaggle.\"\"\"\n",
    "    # Create dataset-metadata.json file\n",
    "    metadata = {\n",
    "        \"title\": dataset_title,\n",
    "        \"id\": \"mahajantm/\" + dataset_id,  # Use correct Kaggle username\n",
    "        \"licenses\": [{\"name\": \"CC0-1.0\"}]\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    # Authenticate and create dataset using Kaggle API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    try:\n",
    "        api.dataset_create_new(\n",
    "            folder=output_dir,\n",
    "            convert_to_csv=False,\n",
    "            dir_mode='zip'\n",
    "        )\n",
    "        print(f\"Successfully created dataset: {dataset_title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    train = pd.read_csv('/kaggle/input/images-hda-before-preprocess/glaucoma_no_mask_train.csv')\n",
    "    test = pd.read_csv('/kaggle/input/images-hda-before-preprocess/glaucoma_no_mask_test.csv')\n",
    "    image_paths = pd.concat([train[['Image Path']], test[['Image Path']]], ignore_index=True)['Image Path'].tolist()\n",
    "    \n",
    "#     image_paths = [\n",
    "#         \"/kaggle/input/jraigs-dataset/justRAIGS/0/0/TRAIN000237.JPG\",\n",
    "#         \"/kaggle/input/jraigs-dataset/justRAIGS/5/TRAIN095425.JPG\"\n",
    "#     ]\n",
    "\n",
    "    output_dir = \"/kaggle/working/preprocessed_images\"  # Use Kaggle's working directory\n",
    "    output_size = 2000\n",
    "    \n",
    "    # Process images\n",
    "    processed_folder_path = process_and_save_images(image_paths, output_dir, output_size)\n",
    "    print(f\"Images processed and saved to: {processed_folder_path}\")\n",
    "    \n",
    "    # Create Kaggle dataset\n",
    "    dataset_title = \"Processed Retinal Images HDA\"\n",
    "    dataset_id = \"processed-retinal-images\"\n",
    "    create_dataset(output_dir, dataset_title, dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191004d",
   "metadata": {
    "papermill": {
     "duration": 1.796932,
     "end_time": "2024-10-25T19:24:20.335509",
     "exception": false,
     "start_time": "2024-10-25T19:24:18.538577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997dd3a8",
   "metadata": {
    "papermill": {
     "duration": 1.795589,
     "end_time": "2024-10-25T19:24:23.827709",
     "exception": false,
     "start_time": "2024-10-25T19:24:22.032120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a742a1",
   "metadata": {
    "papermill": {
     "duration": 1.776766,
     "end_time": "2024-10-25T19:24:27.435469",
     "exception": false,
     "start_time": "2024-10-25T19:24:25.658703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4610776,
     "sourceId": 7860205,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5935443,
     "sourceId": 9705025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5947673,
     "sourceId": 9721148,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5948313,
     "sourceId": 9722016,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5396.038151,
   "end_time": "2024-10-25T19:24:30.338244",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-25T17:54:34.300093",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
