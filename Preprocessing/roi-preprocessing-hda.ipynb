{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451dfe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T10:35:53.602761Z",
     "iopub.status.busy": "2024-11-01T10:35:53.602303Z",
     "iopub.status.idle": "2024-11-01T10:36:11.571230Z",
     "shell.execute_reply": "2024-11-01T10:36:11.569720Z"
    },
    "papermill": {
     "duration": 17.978055,
     "end_time": "2024-11-01T10:36:11.574190",
     "exception": false,
     "start_time": "2024-11-01T10:35:53.596135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95258c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T10:36:11.587539Z",
     "iopub.status.busy": "2024-11-01T10:36:11.587084Z",
     "iopub.status.idle": "2024-11-01T11:12:44.311823Z",
     "shell.execute_reply": "2024-11-01T11:12:44.310038Z"
    },
    "papermill": {
     "duration": 2195.984327,
     "end_time": "2024-11-01T11:12:47.564008",
     "exception": false,
     "start_time": "2024-11-01T10:36:11.579681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "def find_encompassing_bbox(bboxes):\n",
    "    \"\"\"\n",
    "    Find the encompassing bounding box from multiple bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - bboxes: A list of bounding boxes, each in the format [x1, y1, x2, y2].\n",
    "\n",
    "    Returns:\n",
    "    - The encompassing bounding box as [min_x1, min_y1, max_x2, max_y2].\n",
    "    \"\"\"\n",
    "    # Initialize min and max coordinates with the first bounding box\n",
    "    min_x1, min_y1, max_x2, max_y2 = bboxes[0]\n",
    "\n",
    "    for bbox in bboxes[1:]:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        min_x1 = min(min_x1, x1)\n",
    "        min_y1 = min(min_y1, y1)\n",
    "        max_x2 = max(max_x2, x2)\n",
    "        max_y2 = max(max_y2, y2)\n",
    "\n",
    "    return [min_x1, min_y1, max_x2, max_y2]\n",
    "\n",
    "# Function to crop and resize an image\n",
    "def crop_and_resize_image(img, bbox, target_size=(518, 518)):\n",
    "    \"\"\"\n",
    "    Attempts to crop a 518x518 square from the center of a given bounding box. If the square\n",
    "    exceeds image dimensions, it crops the largest possible square and resizes it to 518x518.\n",
    "    If a given bounding box exceeds 518x518, segmentation is considered as invalid.\n",
    "\n",
    "    Parameters:\n",
    "    - img: The preprocessed image read by CV2.\n",
    "    - bbox: The bounding box coordinates as [x1, y1, x2, y2].\n",
    "    - target_size: The target size for cropping and resizing as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    - Resized image if cropping is possible, otherwise None.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    \n",
    "    # Calculate the width and height of the bounding box\n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "\n",
    "    # Check if the bounding box doesn't exceed 518x518\n",
    "    if bbox_width > target_size[0] or bbox_height > target_size[1]:\n",
    "        return None \n",
    "\n",
    "    # Calculate the center of the bounding box\n",
    "    center_x = (x1 + x2) // 2\n",
    "    center_y = (y1 + y2) // 2\n",
    "\n",
    "    # Calculate half the target size\n",
    "    half_target = target_size[0] // 2\n",
    "\n",
    "    # Define initial maximum square crop that can fit within the image boundaries\n",
    "    start_x = max(0, center_x - half_target)\n",
    "    start_y = max(0, center_y - half_target)\n",
    "    end_x = min(img.shape[1], center_x + half_target)\n",
    "    end_y = min(img.shape[0], center_y + half_target)\n",
    "\n",
    "    # Validate crop dimensions\n",
    "    crop_width = end_x - start_x\n",
    "    crop_height = end_y - start_y\n",
    "\n",
    "    # Adjust crop dimensions to the largest possible square within the boundary\n",
    "    if crop_width < target_size[0] or crop_height < target_size[1]:\n",
    "        # Calculate the largest possible dimension that can be squared within the limits\n",
    "        max_possible_square = min(crop_width, crop_height)\n",
    "        start_x = center_x - max_possible_square // 2\n",
    "        start_y = center_y - max_possible_square // 2\n",
    "        end_x = start_x + max_possible_square\n",
    "        end_y = start_y + max_possible_square\n",
    "        # Re-validate boundaries (important in cases where center is near the image edge)\n",
    "        start_x = max(0, start_x)\n",
    "        start_y = max(0, start_y)\n",
    "        end_x = min(img.shape[1], end_x)\n",
    "        end_y = min(img.shape[0], end_y)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_img = img[start_y:end_y, start_x:end_x]\n",
    "    if cropped_img.size == 0:\n",
    "        return None  # Return None if the cropped image is empty\n",
    "\n",
    "    # Resize to the desired target size\n",
    "    resized_img = cv2.resize(cropped_img, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    return resized_img\n",
    "\n",
    "# Function to determine path of an image\n",
    "def determine_path(base_path, eye_id):\n",
    "    base_path = os.path.join(base_path, eye_id)\n",
    "      \n",
    "    for ext in ['.JPG', '.PNG','.JPEG']:\n",
    "        full_path = base_path + ext\n",
    "\n",
    "        if os.path.exists(full_path):\n",
    "              return full_path\n",
    "\n",
    "# Function to apply ROI on all datasets\n",
    "def process_images(dataset, model, base_path_img, save_path, size=(518, 518)):\n",
    "    \"\"\"\n",
    "    Processes and saves images with successful ROI segmentation.\n",
    "\n",
    "    Iterates through the dataset, checks if the image already exists in the save path, and if so, classifies as OD detected.\n",
    "    If not, detects OD using YOLO, and if found, validate bbox size, crops, resizes, and saves the image.\n",
    "    Updates the dataset with ROI detection results.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (DataFrame): Dataset with 'Eye ID' for image processing.\n",
    "        model (YOLO): Pretrained YOLO model for OD detection.\n",
    "        base_path_img (str): Path to the directory containing images.\n",
    "        save_path (str): Path to save processed images.\n",
    "\n",
    "    Returns:\n",
    "        Updated dataset.\n",
    "    \"\"\"\n",
    "    # Ensure the save_path exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "   \n",
    "    od_detected = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        eye_id = row['Eye ID']\n",
    "        output_filename = f\"{eye_id}.JPG\"\n",
    "        output_path = os.path.join(save_path, output_filename)\n",
    "\n",
    "        # Check if the output file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            print(f\"Image for {eye_id} already processed.\")\n",
    "            od_detected.append(1)\n",
    "            continue\n",
    "\n",
    "        # Determine image path\n",
    "        img_path = determine_path(base_path_img, eye_id)\n",
    "        if not img_path:\n",
    "            print(f\"Path for {eye_id} not found.\")\n",
    "            od_detected.append(0)\n",
    "            continue\n",
    "\n",
    "        # Load the preprocessed image\n",
    "        img_array = cv2.imread(img_path)\n",
    "\n",
    "        # Make predictions using YOLO model\n",
    "        results = model(img_array)\n",
    "        boxes = results[0].boxes\n",
    "\n",
    "        # Checking if optic disc was detected\n",
    "        if len(boxes) == 0:\n",
    "            od_detected.append(0)\n",
    "        else:\n",
    "            # Find the encompassing bounding box, crop, resize, and save\n",
    "            bboxes = [box.numpy().tolist() for box in boxes.xyxy]\n",
    "            encompassing_bbox = find_encompassing_bbox(bboxes)\n",
    "            cropped_resized_img = crop_and_resize_image(img_array, encompassing_bbox, target_size=size)\n",
    "            if cropped_resized_img is None:\n",
    "                print(\"BBox was too large\")\n",
    "                od_detected.append(0)\n",
    "            else:\n",
    "                cv2.imwrite(output_path, cropped_resized_img)\n",
    "                od_detected.append(1)\n",
    "\n",
    "    # Update the DataFrame with the OD detection results\n",
    "    dataset['OD'] = od_detected\n",
    "    return dataset\n",
    "\n",
    "def main():\n",
    "    # Initialize YOLO model\n",
    "    model_path = '/kaggle/input/od_segmentation_model/pytorch/default/1/best.pt'\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    file_path_img = '/kaggle/input/preprocessed-image-hda-without-roi/preprocessed_images/'\n",
    "    save_path = '/kaggle/working/ROI_images/'\n",
    "\n",
    "    # Base path for datasets\n",
    "    dataset_base_path = '/kaggle/input/images-hda-before-preprocess/'\n",
    "    os.makedirs('/kaggle/working/masks_csvs', exist_ok=True)\n",
    "\n",
    "    # List of CSV files to read from\n",
    "    input_files = [\n",
    "        'glaucoma_no_mask_test.csv',\n",
    "        'glaucoma_no_mask_train.csv'\n",
    "    ]\n",
    "\n",
    "    # Corresponding output file names\n",
    "    output_files = [\n",
    "        'glaucoma_masks_test.csv',\n",
    "        'glaucoma_masks_train.csv'\n",
    "    ]\n",
    "\n",
    "    # Loop over the file lists, combining with the base path\n",
    "    for input_file, output_file in zip(input_files, output_files):\n",
    "        input_csv = f\"{dataset_base_path}{input_file}\"\n",
    "        output_csv = f\"/kaggle/working/masks_csvs/{output_file}\"\n",
    "        \n",
    "        df_temp = pd.read_csv(input_csv)  # Read the DataFrame\n",
    "        processed_dataset = process_images(df_temp, model, file_path_img, save_path)  # Process images\n",
    "        print(len(processed_dataset))\n",
    "        segmentation_dataset = processed_dataset[processed_dataset[\"OD\"] == 1]  # Filter rows where OD was detected\n",
    "        segmentation_dataset.drop(\"OD\", axis=1, inplace=True)  # Drop the 'OD' column\n",
    "        segmentation_dataset.reset_index(drop=True, inplace=True)  # Reset the DataFrame index\n",
    "        segmentation_dataset.to_csv(output_csv, index=False)  # Save the processed DataFrame\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997d11d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T11:12:53.951551Z",
     "iopub.status.busy": "2024-11-01T11:12:53.951011Z",
     "iopub.status.idle": "2024-11-01T11:12:53.958727Z",
     "shell.execute_reply": "2024-11-01T11:12:53.957344Z"
    },
    "papermill": {
     "duration": 3.210707,
     "end_time": "2024-11-01T11:12:53.961494",
     "exception": false,
     "start_time": "2024-11-01T11:12:50.750787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_on_sample():\n",
    "#     # Initialize YOLO model\n",
    "#     model_path = '/kaggle/input/od_segmentation_model/pytorch/default/1/best.pt'\n",
    "#     model = YOLO(model_path)\n",
    "\n",
    "#     file_path_img = '/kaggle/input/preprocessed-image-hda-without-roi/preprocessed_images/'\n",
    "#     save_path = '/kaggle/working/ROI_images/'\n",
    "\n",
    "#     # Sample DataFrame for testing\n",
    "#     sample_data = {'Eye ID': ['TRAIN000034', 'TRAIN000054', 'TRAIN000060']}\n",
    "#     df_sample = pd.DataFrame(sample_data)\n",
    "\n",
    "#     # Run processing on sample data\n",
    "#     processed_dataset = process_images(df_sample, model, file_path_img, save_path)\n",
    "\n",
    "#     # Save processed results to CSV for inspection\n",
    "#     processed_dataset.to_csv('/kaggle/working/sample_processed.csv', index=False)\n",
    "#     print(\"Test complete. Check './sample_processed.csv' and './ROI_images/' for results.\")\n",
    "\n",
    "# # Run the test\n",
    "# test_on_sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e01e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T11:13:00.530399Z",
     "iopub.status.busy": "2024-11-01T11:13:00.529709Z",
     "iopub.status.idle": "2024-11-01T11:13:00.536442Z",
     "shell.execute_reply": "2024-11-01T11:13:00.535157Z"
    },
    "papermill": {
     "duration": 3.325259,
     "end_time": "2024-11-01T11:13:00.539283",
     "exception": false,
     "start_time": "2024-11-01T11:12:57.214024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'KAGGLE_USERNAME'\n",
    "os.environ['KAGGLE_KEY'] = 'KAGGLE_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9ebf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T11:13:06.868955Z",
     "iopub.status.busy": "2024-11-01T11:13:06.868272Z",
     "iopub.status.idle": "2024-11-01T12:42:03.720271Z",
     "shell.execute_reply": "2024-11-01T12:42:03.718731Z"
    },
    "papermill": {
     "duration": 5346.588743,
     "end_time": "2024-11-01T12:42:10.272737",
     "exception": false,
     "start_time": "2024-11-01T11:13:03.683994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def create_dataset(output_dir, dataset_title, dataset_id):\n",
    "    \"\"\"Creates a new dataset in Kaggle.\"\"\"\n",
    "    # Create dataset-metadata.json file\n",
    "    metadata = {\n",
    "        \"title\": dataset_title,\n",
    "        \"id\": \"mahajantm/\" + dataset_id,  # Use correct Kaggle username\n",
    "        \"licenses\": [{\"name\": \"CC0-1.0\"}]\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    # Authenticate and create dataset using Kaggle API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    try:\n",
    "        api.dataset_create_new(\n",
    "            folder=output_dir,\n",
    "            convert_to_csv=False,\n",
    "            dir_mode='zip'\n",
    "        )\n",
    "        print(f\"Successfully created dataset: {dataset_title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {e}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "output_dir = '/kaggle/working/ROI_images'\n",
    "\n",
    "# Create Kaggle dataset\n",
    "dataset_title = \"ROI Retinal Images HDA\"\n",
    "dataset_id = \"roi-retinal-images\"\n",
    "create_dataset(output_dir, dataset_title, dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e6d31",
   "metadata": {
    "papermill": {
     "duration": 6.461206,
     "end_time": "2024-11-01T12:42:23.187066",
     "exception": false,
     "start_time": "2024-11-01T12:42:16.725860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895faf8",
   "metadata": {
    "papermill": {
     "duration": 6.626755,
     "end_time": "2024-11-01T12:42:36.323190",
     "exception": false,
     "start_time": "2024-11-01T12:42:29.696435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5949106,
     "sourceId": 9722993,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5948313,
     "sourceId": 9725670,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 152943,
     "modelInstanceId": 130089,
     "sourceId": 153165,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7614.100865,
   "end_time": "2024-11-01T12:42:44.297583",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-01T10:35:50.196718",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
