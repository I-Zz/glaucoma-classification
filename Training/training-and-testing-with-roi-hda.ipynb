{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9722993,"sourceType":"datasetVersion","datasetId":5949106},{"sourceId":9725670,"sourceType":"datasetVersion","datasetId":5948313},{"sourceId":9781986,"sourceType":"datasetVersion","datasetId":5992903},{"sourceId":9788654,"sourceType":"datasetVersion","datasetId":5964505}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/roi-images-hda/masks_csvs/glaucoma_masks_train.csv')\n\n# Count rows where 'Final Label' is 1 and 0\ncount_label_1 = len(df[df['Final Label'] == 1])\ncount_label_0 = len(df[df['Final Label'] == 0])\n\nprint(f\"Count of rows with Final Label == 1: {count_label_1}\")\nprint(f\"Count of rows with Final Label == 0: {count_label_0}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:23:50.892400Z","iopub.execute_input":"2024-11-07T18:23:50.893158Z","iopub.status.idle":"2024-11-07T18:23:52.555139Z","shell.execute_reply.started":"2024-11-07T18:23:50.893096Z","shell.execute_reply":"2024-11-07T18:23:52.554123Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torchvision.transforms import autoaugment\n\ndef train_transform():\n    return transforms.Compose([\n        transforms.Resize((384, 384), interpolation=transforms.InterpolationMode.BICUBIC),\n        autoaugment.AutoAugment(autoaugment.AutoAugmentPolicy.IMAGENET),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\ndef test_transform():\n    return transforms.Compose([\n        transforms.Resize((384, 384), interpolation=transforms.InterpolationMode.BICUBIC),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\nclass GlaucomaDataset(Dataset):\n    \"\"\"\n    Args:\n        dataframe (DataFrame): DataFrame containing the dataset information.\n        img_folder (string): Directory with all the images.\n        transform (callable, optional): Optional transform to be applied on a sample.\n        extra_features (list of str, optional): Column names for the extra features.\n    \"\"\"\n    def __init__(self, dataframe, img_folder, transform=None, extra_features=None):\n        self.dataframe = dataframe\n        self.img_folder = img_folder\n        self.transform = transform\n        self.extra_features = extra_features\n        \n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_id = self.dataframe.iloc[idx]['Eye ID']\n        for ext in ['.JPG','.JPEG', '.PNG', '.png', '.jpg', '.jpeg']:\n            img_path = os.path.join(self.img_folder, f\"{img_id}{ext}\")\n            if os.path.exists(img_path):\n                break\n        else:\n            raise FileNotFoundError(f\"No image found for ID {img_id} with any supported extension.\")\n\n        image = Image.open(img_path)\n        if self.transform:\n            image = self.transform(image)\n\n        # Handling extra features \n        if self.extra_features == None :\n            img_class = self.dataframe.iloc[idx]['Final Label']\n            labels = torch.tensor(img_class, dtype=torch.float32)\n        else:           \n            extra_labels = self.dataframe.iloc[idx][self.extra_features].values.astype(float)\n            labels = torch.tensor(extra_labels, dtype=torch.float32)\n        \n        return image, labels","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:24:29.271578Z","iopub.execute_input":"2024-11-07T18:24:29.272292Z","iopub.status.idle":"2024-11-07T18:24:29.285114Z","shell.execute_reply.started":"2024-11-07T18:24:29.272253Z","shell.execute_reply":"2024-11-07T18:24:29.284269Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimage = Image.open('/kaggle/input/roi-images-hda/ROI_images/TRAIN000054.JPG')\nprint(image.size)","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:24:10.878708Z","iopub.execute_input":"2024-11-07T18:24:10.879260Z","iopub.status.idle":"2024-11-07T18:24:10.912642Z","shell.execute_reply.started":"2024-11-07T18:24:10.879213Z","shell.execute_reply":"2024-11-07T18:24:10.911679Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import re\n# import pandas as pd\n# import torch\n# import torch.nn as nn\n# import torch.optim\n# from torch.utils.data import DataLoader, random_split\n# from torchvision.models import vit_b_16, ViT_B_16_Weights\n# from torch.cuda.amp import GradScaler, autocast\n# from tqdm import tqdm\n# from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n\n# model_name = \"ViT_RG_ROI\"\n# model_save_directory = f'/kaggle/working/model/{model_name}'\n# img_folder = '/kaggle/input/roi-images-hda/ROI_images'\n# train_df = pd.read_csv('/kaggle/input/roi-images-hda/masks_csvs/glaucoma_masks_train.csv')\n\n# best_model_directory = os.path.join('/kaggle/working/', 'best_model')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T15:04:32.736672Z","iopub.execute_input":"2024-11-02T15:04:32.737067Z","iopub.status.idle":"2024-11-02T15:04:32.758067Z","shell.execute_reply.started":"2024-11-02T15:04:32.737030Z","shell.execute_reply":"2024-11-02T15:04:32.757308Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import re\n# import pandas as pd\n# import torch\n# import torch.nn as nn\n# import torch.optim\n# from torch.utils.data import DataLoader, random_split\n# from torchvision.models import vit_b_16, ViT_B_16_Weights\n# from torch.cuda.amp import GradScaler, autocast\n# from tqdm import tqdm\n# from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n\n# ################### Configuration ###################\n# model_name = \"ViT_RG_ROI\"\n# model_save_directory = f'/kaggle/working/model/{model_name}'\n# img_folder = '/kaggle/input/roi-images-hda/ROI_images'\n# train_df = pd.read_csv('/kaggle/input/roi-images-hda/masks_csvs/glaucoma_masks_train.csv')\n\n# best_model_directory = os.path.join('/kaggle/working/', 'best_model')\n\n# if not os.path.exists(best_model_directory):\n#     os.makedirs(best_model_directory)\n\n# # Hyperparameters for early stopping\n# eval_every = 5  # Evaluate on validation set every 5 epochs\n# patience = 5    # Early stopping patience\n# num_epochs = 100  # Total training epochs\n\n# # Check for or create save directory\n# if not os.path.exists(model_save_directory):\n#     os.makedirs(model_save_directory)\n\n# ################### Dataset and Dataloaders ###################\n# # Initialize dataset with transformations\n# train_dataset = GlaucomaDataset(dataframe=train_df, img_folder=img_folder, transform=train_transform(), extra_features=None)\n\n# # Split train_dataset into training and validation sets\n# train_size = int(0.8 * len(train_dataset))\n# val_size = len(train_dataset) - train_size\n# train_data, val_data = random_split(train_dataset, [train_size, val_size])\n\n# # Dataloaders for training and validation\n# train_loader = DataLoader(train_data, batch_size=20, shuffle=True, num_workers=8)\n# val_loader = DataLoader(val_data, batch_size=20, shuffle=False, num_workers=8)\n\n# ################### Model Initialization ###################\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# weights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\n# model = vit_b_16(weights=weights)\n\n# # Update the model's final layer for binary classification\n# num_features = model.heads.head.in_features\n# model.heads.head = nn.Linear(num_features, 1)\n\n# # Freeze all layers except the classifier head\n# for name, param in model.named_parameters():\n#     if 'heads.head' not in name:\n#         param.requires_grad = False\n\n# if torch.cuda.device_count() > 1:\n#     print(f\"Using {torch.cuda.device_count()} GPUs!\")\n#     model = nn.DataParallel(model)\n\n# model.to(device)\n\n# ################### Loss and Optimizer ###################\n# # Compute class weights for weighted BCE loss\n# negative_class = len(train_df[train_df['Final Label'] == 0])\n# positive_class = len(train_df[train_df['Final Label'] == 1])\n# pos_weight_value = negative_class / positive_class\n# pos_weight_tensor = torch.tensor([pos_weight_value], dtype=torch.float, device=device)\n# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n\n# # Parameter groups for differential learning rates\n# if torch.cuda.device_count() > 1:\n#     base_params = [p for n, p in model.module.named_parameters() if 'heads.head' not in n]\n#     classifier_params = model.module.heads.head.parameters()\n# else:\n#     base_params = [p for n, p in model.named_parameters() if 'heads.head' not in n]\n#     classifier_params = model.heads.head.parameters()\n\n# optimizer = torch.optim.AdamW([\n#     {'params': base_params, 'lr': 1e-5, 'weight_decay': 1e-4},\n#     {'params': classifier_params, 'lr': 1e-4, 'weight_decay': 1e-4}\n# ])\n\n# ################### Load Model Checkpoint (if exists) ###################\n# latest_model_path = None\n# start_epoch = 0\n\n# for file in os.listdir(model_save_directory):\n#     if file.startswith(f\"{model_name}_epoch_\") and file.endswith(\".pth\"):\n#         epoch_num = int(re.findall(r\"\\d+\", file)[0])\n#         if epoch_num > start_epoch:\n#             start_epoch = epoch_num\n#             latest_model_path = os.path.join(model_save_directory, file)\n#             print(latest_model_path)\n\n# if latest_model_path:\n#     model.load_state_dict(torch.load(latest_model_path))\n#     print(f\"Loaded model from {latest_model_path}, continuing training from epoch {start_epoch+1}\")\n# else:\n#     print(\"No saved model found, starting training from scratch\")\n\n\n# ################### Training Loop with Early Stopping ###################\n# scaler = GradScaler()\n# best_val_auc = 0  # Track best AUC score for early stopping\n# epochs_no_improve = 0\n\n# for epoch in range(start_epoch, num_epochs):\n#     model.train()\n#     train_loss = 0.0\n\n#     progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n#     for batch_idx, (images, labels) in progress_bar:\n#         images, labels = images.to(device), labels.to(device)\n        \n#         optimizer.zero_grad()\n\n#         with autocast():\n#             outputs = model(images)\n#             loss = criterion(outputs.squeeze(), labels.float())\n\n#         scaler.scale(loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n\n#         train_loss += loss.item() * images.size(0)\n#         progress_bar.set_postfix({'train_loss': loss.item()})\n\n#     train_loss /= len(train_loader.dataset)\n\n#     # Save model after each epoch\n#     if (epoch + 1) % 10 == 0:\n#         epoch_save_path = os.path.join(model_save_directory, f\"{model_name}_epoch_{epoch + 1}.pth\")\n#         torch.save(model.state_dict(), epoch_save_path)\n#         print(f\"Model saved to {epoch_save_path} after epoch {epoch + 1}\")\n\n#     # Validation and Early Stopping\n#     if (epoch + 1) % eval_every == 0:\n#         model.eval()\n#         val_loss = 0.0\n#         all_labels = []\n#         all_preds = []\n\n#         with torch.no_grad():\n#             for images, labels in val_loader:\n#                 images, labels = images.to(device), labels.to(device)\n#                 with autocast():\n#                     outputs = model(images)\n#                     loss = criterion(outputs.squeeze(), labels.float())\n                \n#                 val_loss += loss.item() * images.size(0)\n#                 preds = torch.sigmoid(outputs).squeeze().cpu().numpy()\n                \n#                 all_labels.extend(labels.cpu().numpy())\n#                 all_preds.extend(preds)\n\n#         val_loss /= len(val_loader.dataset)\n\n#         # Calculate metrics\n#         val_auc = roc_auc_score(all_labels, all_preds)\n#         val_f1 = f1_score(all_labels, (np.array(all_preds) > 0.5).astype(int))\n#         val_precision = precision_score(all_labels, (np.array(all_preds) > 0.5).astype(int))\n#         val_recall = recall_score(all_labels, (np.array(all_preds) > 0.5).astype(int))\n\n#         print(f\"Validation AUC after epoch {epoch + 1}: {val_auc}\")\n#         print(f\"Validation F1 Score: {val_f1}, Precision: {val_precision}, Recall: {val_recall}\")\n\n#         # Early stopping check\n#         if val_auc > best_val_auc:\n#             best_val_auc = val_auc\n#             epochs_no_improve = 0\n#             print(f\"New best AUC: {best_val_auc}\")\n            \n#             best_model_path = os.path.join(best_model_directory, f\"{model_name}_best.pth\")\n#             torch.save(model.state_dict(), best_model_path)\n#             print(f\"Best model saved to {best_model_path}\")\n#         else:\n#             epochs_no_improve += 1\n#             print(f\"No improvement for {epochs_no_improve} validation checks.\")\n\n#         if epochs_no_improve >= patience:\n#             print(f\"Early stopping triggered. No improvement for {patience} validation checks.\")\n#             break\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T11:07:33.907224Z","iopub.execute_input":"2024-11-02T11:07:33.907694Z","iopub.status.idle":"2024-11-02T11:07:43.412052Z","shell.execute_reply.started":"2024-11-02T11:07:33.907649Z","shell.execute_reply":"2024-11-02T11:07:43.409629Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# THIS FOR GENERATING GRAPHS WHILE TRAINING","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n################### Configuration ###################\nmodel_name = \"ViT_RG_ROI\"\nmodel_save_directory = f'/kaggle/working/model/{model_name}'\nimg_folder = '/kaggle/input/roi-images-hda/ROI_images'\ntrain_df = pd.read_csv('/kaggle/input/roi-images-hda/masks_csvs/glaucoma_masks_train.csv')\n\nbest_model_directory = os.path.join('/kaggle/working/', 'best_model')\n\nif not os.path.exists(best_model_directory):\n    os.makedirs(best_model_directory)\n\n# Hyperparameters for early stopping\neval_every = 5  # Evaluate on validation set every 5 epochs\npatience = 5    # Early stopping patience\nnum_epochs = 100  # Total training epochs\n\n# Check for or create save directory\nif not os.path.exists(model_save_directory):\n    os.makedirs(model_save_directory)\n\n################### Dataset and Dataloaders ###################\n# Initialize dataset with transformations\ntrain_dataset = GlaucomaDataset(dataframe=train_df, img_folder=img_folder, transform=train_transform(), extra_features=None)\n\n# Split train_dataset into training and validation sets\ntrain_size = int(0.8 * len(train_dataset))\nval_size = len(train_dataset) - train_size\ntrain_data, val_data = random_split(train_dataset, [train_size, val_size])\n\n# Dataloaders for training and validation\ntrain_loader = DataLoader(train_data, batch_size=20, shuffle=True, num_workers=8)\nval_loader = DataLoader(val_data, batch_size=20, shuffle=False, num_workers=8)\n\n################### Model Initialization ###################\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nweights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\nmodel = vit_b_16(weights=weights)\n\n# Update the model's final layer for binary classification\nnum_features = model.heads.head.in_features\nmodel.heads.head = nn.Linear(num_features, 1)\n\n# Freeze all layers except the classifier head\nfor name, param in model.named_parameters():\n    if 'heads.head' not in name:\n        param.requires_grad = False\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\n\nmodel.to(device)\n\n################### Loss and Optimizer ###################\n# Compute class weights for weighted BCE loss\nnegative_class = len(train_df[train_df['Final Label'] == 0])\npositive_class = len(train_df[train_df['Final Label'] == 1])\npos_weight_value = negative_class / positive_class\npos_weight_tensor = torch.tensor([pos_weight_value], dtype=torch.float, device=device)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n\n# Parameter groups for differential learning rates\nif torch.cuda.device_count() > 1:\n    base_params = [p for n, p in model.module.named_parameters() if 'heads.head' not in n]\n    classifier_params = model.module.heads.head.parameters()\nelse:\n    base_params = [p for n, p in model.named_parameters() if 'heads.head' not in n]\n    classifier_params = model.heads.head.parameters()\n\noptimizer = torch.optim.AdamW([\n    {'params': base_params, 'lr': 1e-5, 'weight_decay': 1e-4},\n    {'params': classifier_params, 'lr': 1e-4, 'weight_decay': 1e-4}\n])\n\n################### Load Model Checkpoint (if exists) ###################\nlatest_model_path = None\nstart_epoch = 0\n\nfor file in os.listdir(model_save_directory):\n    if file.startswith(f\"{model_name}_epoch_\") and file.endswith(\".pth\"):\n        epoch_num = int(re.findall(r\"\\d+\", file)[0])\n        if epoch_num > start_epoch:\n            start_epoch = epoch_num\n            latest_model_path = os.path.join(model_save_directory, file)\n            print(latest_model_path)\n\nif latest_model_path:\n    model.load_state_dict(torch.load(latest_model_path))\n    print(f\"Loaded model from {latest_model_path}, continuing training from epoch {start_epoch+1}\")\nelse:\n    print(\"No saved model found, starting training from scratch\")\n\n################### Training Loop with Early Stopping ###################\nscaler = GradScaler()\nbest_val_auc = 0  # Track best AUC score for early stopping\nepochs_no_improve = 0\n\n# Initialize lists to track metrics\ntrain_losses = []\nval_losses = []\nval_aucs = []\nval_f1s = []\nval_precisions = []\nval_recalls = []\nval_epochs = []  # Track epochs for validation metrics\n\nfor epoch in range(start_epoch, num_epochs):\n    model.train()\n    train_loss = 0.0\n\n    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n    for batch_idx, (images, labels) in progress_bar:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs.squeeze(), labels.float())\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        train_loss += loss.item() * images.size(0)\n        progress_bar.set_postfix({'train_loss': loss.item()})\n\n    train_loss /= len(train_loader.dataset)\n    train_losses.append(train_loss)  # Store train loss for each epoch\n\n    # Validation and Early Stopping\n    if (epoch + 1) % eval_every == 0:\n        val_epochs.append(epoch + 1)  # Track the epochs at which validation is done\n        model.eval()\n        val_loss = 0.0\n        all_labels = []\n        all_preds = []\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                with autocast():\n                    outputs = model(images)\n                    loss = criterion(outputs.squeeze(), labels.float())\n\n                val_loss += loss.item() * images.size(0)\n                preds = torch.sigmoid(outputs).squeeze().cpu().numpy()\n\n                all_labels.extend(labels.cpu().numpy())\n                all_preds.extend(preds)\n\n        val_loss /= len(val_loader.dataset)\n        val_losses.append(val_loss)  # Store validation loss for each eval cycle\n\n        # Calculate metrics\n        val_auc = roc_auc_score(all_labels, all_preds)\n        val_f1 = f1_score(all_labels, (np.array(all_preds) > 0.5).astype(int))\n        val_precision = precision_score(all_labels, (np.array(all_preds) > 0.5).astype(int))\n        val_recall = recall_score(all_labels, (np.array(all_preds) > 0.5).astype(int))\n\n        # Append metrics for plotting\n        val_aucs.append(val_auc)\n        val_f1s.append(val_f1)\n        val_precisions.append(val_precision)\n        val_recalls.append(val_recall)\n\n        print(f\"Validation AUC after epoch {epoch + 1}: {val_auc}\")\n        print(f\"Validation F1 Score: {val_f1}, Precision: {val_precision}, Recall: {val_recall}\")\n\n        # Early stopping check\n        if val_auc > best_val_auc:\n            best_val_auc = val_auc\n            epochs_no_improve = 0\n            print(f\"New best AUC: {best_val_auc}\")\n\n            best_model_path = os.path.join(best_model_directory, f\"{model_name}_best.pth\")\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Best model saved to {best_model_path}\")\n        else:\n            epochs_no_improve += 1\n            print(f\"No improvement for {epochs_no_improve} validation checks.\")\n\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered. No improvement for {patience} validation checks.\")\n            break\n\n# Plotting metrics after training\nepochs = range(1, len(train_losses) + 1)  # Training epochs\n\nplt.figure(figsize=(12, 8))\n\n# Plot training and validation loss\nplt.subplot(2, 2, 1)\nplt.plot(epochs, train_losses, label='Training Loss')\nplt.plot(val_epochs, val_losses, label='Validation Loss')  # Use val_epochs for validation metrics\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot validation AUC\nplt.subplot(2, 2, 2)\nplt.plot(val_epochs, val_aucs, label='Validation AUC')  # Use val_epochs for validation metrics\nplt.xlabel('Epochs')\nplt.ylabel('AUC')\nplt.title('Validation AUC over Epochs')\nplt.legend()\n\n# Plot F1 Score\nplt.subplot(2, 2, 3)\nplt.plot(val_epochs, val_f1s, label='Validation F1 Score')  # Use val_epochs for validation metrics\nplt.xlabel('Epochs')\nplt.ylabel('F1 Score')\nplt.title('Validation F1 Score over Epochs')\nplt.legend()\n\n# Plot Precision and Recall\nplt.subplot(2, 2, 4)\nplt.plot(val_epochs, val_precisions, label='Validation Precision')  # Use val_epochs for validation metrics\nplt.plot(val_epochs, val_recalls, label='Validation Recall')  # Use val_epochs for validation metrics\nplt.xlabel('Epochs')\nplt.ylabel('Score')\nplt.title('Validation Precision and Recall over Epochs')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-07T18:58:31.647177Z","iopub.execute_input":"2024-11-07T18:58:31.647908Z","iopub.status.idle":"2024-11-07T19:08:34.183739Z","shell.execute_reply.started":"2024-11-07T18:58:31.647861Z","shell.execute_reply":"2024-11-07T19:08:34.182485Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import re\n# import pandas as pd\n# import torch\n# import torch.nn as nn\n# import torch.optim\n# from torch.utils.data import DataLoader, random_split\n# from torchvision.models import vit_l_16, ViT_L_16_Weights\n# from torch.cuda.amp import GradScaler, autocast\n# from tqdm import tqdm\n\n\n# ################### Configuration ###################\n# model_name = \"ViT_RG_ROI\"\n# model_save_directory = f'/kaggle/working/model/{model_name}'\n# img_folder = '/kaggle/input/roi-images-hda/ROI_images'\n# train_df = pd.read_csv('/kaggle/input/roi-images-hda/masks_csvs/glaucoma_masks_train.csv')\n# # val_df = pd.read_csv('./Datasets/glaucoma_masks_val.csv')  # if you use a separate validation set\n\n# best_model_directory = os.path.join('/kaggle/working/best_model', 'best_model')\n# if not os.path.exists(best_model_directory):\n#     os.makedirs(best_model_directory)\n\n# # Hyperparameters for early stopping\n# eval_every = 5  # Evaluate on validation set every 5 epochs\n# patience = 5    # Early stopping patience\n# num_epochs = 100  # Total training epochs\n\n# # Check for or create save directory\n# if not os.path.exists(model_save_directory):\n#     os.makedirs(model_save_directory)\n\n# ################### Dataset and Dataloaders ###################\n# # Initialize dataset with transformations\n# train_dataset = GlaucomaDataset(dataframe=train_df, img_folder=img_folder, transform=train_transform(), extra_features=None)\n\n# # Split train_dataset into training and validation sets\n# train_size = int(0.8 * len(train_dataset))\n# val_size = len(train_dataset) - train_size\n# train_data, val_data = random_split(train_dataset, [train_size, val_size])\n\n# # Dataloaders for training and validation\n# train_loader = DataLoader(train_data, batch_size=20, shuffle=True, num_workers=8)\n# val_loader = DataLoader(val_data, batch_size=20, shuffle=False, num_workers=8)\n\n# ################### Model Initialization ###################\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# weights = ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1\n# model = vit_l_16(weights=weights)\n\n# # Update the model's final layer for binary classification\n# num_features = model.heads.head.in_features\n# model.heads.head = nn.Linear(num_features, 1)\n\n# if torch.cuda.device_count() > 1:\n#     print(f\"Using {torch.cuda.device_count()} GPUs!\")\n#     model = nn.DataParallel(model)\n\n# model.to(device)\n# # Check if ViT weights are frozen or trainable\n# for name, param in model.named_parameters():\n#     print(f\"{name}: {'trainable' if param.requires_grad else 'frozen'}\")\n\n\n# ################### Loss and Optimizer ###################\n# # Compute class weights for weighted BCE loss\n# negative_class = len(train_df[train_df['Final Label'] == 0])\n# positive_class = len(train_df[train_df['Final Label'] == 1])\n# pos_weight_value = negative_class / positive_class\n# pos_weight_tensor = torch.tensor([pos_weight_value], dtype=torch.float, device=device)\n# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n\n# # Parameter groups for differential learning rates\n# if torch.cuda.device_count() > 1:\n#     base_params = [p for n, p in model.module.named_parameters() if 'heads.head' not in n]\n#     classifier_params = model.module.heads.head.parameters()\n# else:\n#     base_params = [p for n, p in model.named_parameters() if 'heads.head' not in n]\n#     classifier_params = model.heads.head.parameters()\n\n# optimizer = torch.optim.AdamW([\n#     {'params': base_params, 'lr': 1e-5, 'weight_decay': 1e-4},\n#     {'params': classifier_params, 'lr': 1e-4, 'weight_decay': 1e-4}\n# ])\n\n# ################### Load Model Checkpoint (if exists) ###################\n# latest_model_path = None\n# start_epoch = 0\n# for file in os.listdir(model_save_directory):\n#     if file.startswith(f\"{model_name}_epoch_\") and file.endswith(\".pth\"):\n#         epoch_num = int(re.findall(r\"\\d+\", file)[0])\n#         if epoch_num > start_epoch:\n#             start_epoch = epoch_num\n#             latest_model_path = os.path.join(model_save_directory, file)\n\n# if latest_model_path:\n#     model.load_state_dict(torch.load(latest_model_path))\n#     print(f\"Loaded model from {latest_model_path}, continuing training from epoch {start_epoch + 1}\")\n# else:\n#     print(\"No saved model found, starting training from scratch\")\n\n# ################### Training Loop with Early Stopping ###################\n# scaler = GradScaler()\n# best_val_loss = float(\"inf\")\n# epochs_no_improve = 0\n\n# for epoch in range(start_epoch, num_epochs):\n#     model.train()\n#     train_loss = 0.0\n\n#     progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}\")\n#     for batch_idx, (images, labels) in progress_bar:\n#         images, labels = images.to(device), labels.to(device)\n        \n#         optimizer.zero_grad()\n\n#         with autocast():\n#             outputs = model(images)\n#             loss = criterion(outputs.squeeze(), labels.float())\n\n#         scaler.scale(loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n\n#         train_loss += loss.item() * images.size(0)\n#         progress_bar.set_postfix({'train_loss': loss.item()})\n\n#     train_loss /= len(train_loader.dataset)\n\n#     # Save model after each epoch\n#     epoch_save_path = os.path.join(model_save_directory, f\"{model_name}_epoch_{epoch + 1}.pth\")\n#     torch.save(model.state_dict(), epoch_save_path)\n#     print(f\"Model saved to {epoch_save_path} after epoch {epoch + 1}\")\n\n#     # Validation and Early Stopping\n#     if (epoch + 1) % eval_every == 0:\n#         model.eval()\n#         val_loss = 0.0\n#         with torch.no_grad():\n#             for images, labels in val_loader:\n#                 images, labels = images.to(device), labels.to(device)\n#                 with autocast():\n#                     outputs = model(images)\n#                     loss = criterion(outputs.squeeze(), labels.float())\n#                 val_loss += loss.item() * images.size(0)\n        \n#         val_loss /= len(val_loader.dataset)\n#         print(f\"Validation loss after epoch {epoch + 1}: {val_loss}\")\n\n#         # Early stopping check\n#         if val_loss < best_val_loss:\n#             best_val_loss = val_loss\n#             epochs_no_improve = 0\n#             print(f\"New best validation loss: {best_val_loss}\")\n            \n#             best_model_path = os.path.join(best_model_directory, f\"{model_name}_best.pth\")\n#             torch.save(model.state_dict(), best_model_path)\n#             print(f\"Best model saved to {best_model_path}\")\n#         else:\n#             epochs_no_improve += 1\n#             print(f\"No improvement for {epochs_no_improve} validation checks.\")\n\n#         if epochs_no_improve >= patience:\n#             print(f\"Early stopping triggered. No improvement for {patience} validation checks.\")\n#             break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# import torch\n# import torch.nn as nn\n# import torch.optim\n# from torchvision.models import vit_l_16, ViT_L_16_Weights\n# from torchvision.models import vit_b_16, ViT_B_16_Weights\n# from torch.utils.data import DataLoader\n# from torch.cuda.amp import GradScaler, autocast\n# from tqdm import tqdm\n# import re\n\n\n\n# ################ Adjust this section as needed ################\n# model_name = \"ViT_RG_NO_ROI\"\n# model_save_directory = f'/kaggle/working/model/{model_name}'\n# img_folder = '/kaggle/input/preprocessed-image-hda-without-roi/preprocessed_images' \n# train_df = pd.read_csv('/kaggle/input/images-hda-before-preprocess/glaucoma_no_mask_train.csv')\n# ###############################################################\n\n# if not os.path.exists(model_save_directory):\n#     os.makedirs(model_save_directory)\n\n# train_dataset = GlaucomaDataset(dataframe=train_df, img_folder=img_folder, transform=train_transform(), extra_features=None)\n# train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=8) \n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # weights = ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1\n\n# # model = vit_l_16(weights=weights)\n# weights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\n# model = vit_b_16(weights=weights)\n\n# num_features = model.heads.head.in_features  \n# model.heads.head = nn.Linear(num_features, 1)\n\n# if torch.cuda.device_count() > 1:\n#     print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n#     model = nn.DataParallel(model)\n\n# model.to(device)\n\n# # Define weights and weighted BCELoss\n# negative_class = len(train_df[train_df['Final Label'] == 0])\n# positive_class = len(train_df[train_df['Final Label'] == 1])\n# pos_weight_value = negative_class / positive_class\n# pos_weight_tensor = torch.tensor([pos_weight_value], dtype=torch.float, device=device)\n# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n\n# # Accessing parameters after applying DataParallel\n# if torch.cuda.device_count() > 1:\n#     base_params = [p for n, p in model.module.named_parameters() if 'heads.head' not in n]\n#     classifier_params = model.module.heads.head.parameters()\n# else:\n#     base_params = [p for n, p in model.named_parameters() if 'heads.head' not in n]\n#     classifier_params = model.heads.head.parameters()\n\n# # Define an AdamW optimizer with differential learning rate and weight decay\n# optimizer = torch.optim.AdamW([\n#     {'params': base_params, 'lr': 1e-5, 'weight_decay': 1e-4},\n#     {'params': classifier_params, 'lr': 1e-4, 'weight_decay': 1e-4}\n# ])\n\n# # Load the latest checkpoint if exists\n# latest_model_path = None\n# start_epoch = 0\n\n# patience = 10  # Number of epochs to wait before stopping when there is no improvement\n# epochs_no_improve = 0  \n\n# for file in os.listdir(model_save_directory):\n#     if file.startswith(f\"{model_name}_epoch_\") and file.endswith(\".pth\"):\n#         epoch_num = int(re.findall(r\"\\d+\", file)[0])\n#         if epoch_num > start_epoch:\n#             start_epoch = epoch_num\n#             latest_model_path = os.path.join(model_save_directory, file)\n\n# if latest_model_path:\n#     model.load_state_dict(torch.load(latest_model_path))\n#     print(f\"Loaded model from {latest_model_path}, continuing training from epoch {start_epoch+1}\")\n# else:\n#     print(\"No saved model found, starting training from scratch\")\n\n# scaler = GradScaler()\n# num_epochs = 100\n# best_loss = float('inf')  # Initialize best loss for validation-based saving\n# save_interval = 10        # Adjust the interval to save model periodically\n\n# # Training and validation loop\n# for epoch in range(start_epoch, num_epochs):\n#     model.train()\n#     train_loss = 0.0\n\n#     progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}\")\n#     for batch_idx, (images, labels) in progress_bar:\n#         images, labels = images.to(device), labels.to(device)\n\n#         optimizer.zero_grad()\n\n#         with autocast():\n#             outputs = model(images)\n#             loss = criterion(outputs.squeeze(), labels.float())\n\n#         scaler.scale(loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n\n#         train_loss += loss.item() * images.size(0)\n#         progress_bar.set_postfix({'train_loss': loss.item()})\n\n#     train_loss /= len(train_loader.dataset)\n#     print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n\n#     # Save model if current loss is the best\n#     best_model_save_directory = '/kaggle/working/best_models/'\n#     if not os.path.exists(best_model_save_directory):\n#         os.makedirs(best_model_save_directory)\n\n#     # Use best_model_save_directory instead of model_save_directory\n# #     best_model_path = os.path.join(best_model_save_directory, f\"{model_name}_best.pth\")\n\n#     if train_loss < best_loss:\n#         best_loss = train_loss\n\n#         best_model_path = os.path.join(best_model_save_directory, f\"{model_name}_best.pth\")\n#         torch.save(model.state_dict(), best_model_path)\n#         print(f\"New best model saved to {best_model_path} with loss {best_loss:.4f}\")\n#         epochs_no_improve = 0 \n#     else:\n#         epochs_no_improve += 1\n#         print(f\"No improvement in loss for {epochs_no_improve} epoch(s).\")\n\n#     # Save every `save_interval` epochs\n#     if (epoch + 1) % save_interval == 0:\n#         epoch_save_path = os.path.join(model_save_directory, f\"{model_name}_epoch_{epoch+1}.pth\")\n#         torch.save(model.state_dict(), epoch_save_path)\n#         print(f\"Model checkpoint saved to {epoch_save_path} at epoch {epoch+1}\")\n    \n#     if epochs_no_improve >= patience:\n#         print(f\"Early stopping triggered. No improvement in loss for {patience} consecutive epochs.\")\n#         break\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# for Best model\n","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nimport numpy as np\n\n# Assuming test_df and img_folder paths are defined, and you have a test dataset loader\ntest_df = pd.read_csv('/kaggle/input/roi-images-hda/masks_csvs/glaucoma_masks_test.csv')  # Path to test CSV\ntest_dataset = GlaucomaDataset(dataframe=test_df, img_folder=img_folder, transform=test_transform(), extra_features=None)\ntest_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=8)\n\n# best_model_directory = '/kaggle/input/model-for-hda/best_model/'\n\n# Load the best model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1)\n\n# Update the model's final layer for binary classification\nnum_features = model.heads.head.in_features\nmodel.heads.head = nn.Linear(num_features, 1)\n\nbest_model_path = os.path.join(best_model_directory, f\"{model_name}_best.pth\")\nmodel.load_state_dict(torch.load(best_model_path))\nmodel.to(device)\nmodel.eval()\n\n# Initialize lists to collect true labels and predictions\nall_labels = []\nall_preds = []\n\n# Testing loop\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        # Get predictions\n        outputs = model(images)\n        preds = torch.sigmoid(outputs).squeeze().cpu().numpy()  # Apply sigmoid to get probabilities\n        \n        # Store labels and predictions\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds)\n\n# Convert predictions to binary classes with a threshold of 0.5\nbinary_preds = (np.array(all_preds) > 0.5).astype(int)\n\n# Calculate metrics\ntest_accuracy = accuracy_score(all_labels, binary_preds)\ntest_precision = precision_score(all_labels, binary_preds)\ntest_recall = recall_score(all_labels, binary_preds)\ntest_f1 = f1_score(all_labels, binary_preds)\ntest_auc = roc_auc_score(all_labels, all_preds)\n\n# Print the results\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision: {test_precision:.4f}\")\nprint(f\"Test Recall: {test_recall:.4f}\")\nprint(f\"Test F1 Score: {test_f1:.4f}\")\nprint(f\"Test AUC-ROC: {test_auc:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:23:16.944263Z","iopub.execute_input":"2024-11-02T09:23:16.944640Z","iopub.status.idle":"2024-11-02T09:23:34.914155Z","shell.execute_reply.started":"2024-11-02T09:23:16.944603Z","shell.execute_reply":"2024-11-02T09:23:34.913078Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming test_df and img_folder paths are defined, and you have a test dataset loader\ntest_df = pd.read_csv('/kaggle/input/roi-images-hda/masks_csvs/glaucoma_masks_test.csv')  # Path to test CSV\ntest_dataset = GlaucomaDataset(dataframe=test_df, img_folder=img_folder, transform=test_transform(), extra_features=None)\ntest_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=8)\n\n# best_model_directory = '/kaggle/input/model-for-hda/best_model/'\n\n# Load the best model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1)\n\n# Update the model's final layer for binary classification\nnum_features = model.heads.head.in_features\nmodel.heads.head = nn.Linear(num_features, 1)\n\nbest_model_path = os.path.join(best_model_directory, f\"{model_name}_best.pth\")\nmodel.load_state_dict(torch.load(best_model_path))\nmodel.to(device)\nmodel.eval()\n\n# Initialize lists to collect true labels and predictions\nall_labels = []\nall_preds = []\n\n# Testing loop\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        # Get predictions\n        outputs = model(images)\n        preds = torch.sigmoid(outputs).squeeze().cpu().numpy()  # Apply sigmoid to get probabilities\n        \n        # Store labels and predictions\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds)\n\n# Convert predictions to binary classes with a threshold of 0.5\nbinary_preds = (np.array(all_preds) > 0.5).astype(int)\n\n# Calculate metrics\ntest_accuracy = accuracy_score(all_labels, binary_preds)\ntest_precision = precision_score(all_labels, binary_preds)\ntest_recall = recall_score(all_labels, binary_preds)\ntest_f1 = f1_score(all_labels, binary_preds)\ntest_auc = roc_auc_score(all_labels, all_preds)\nconf_matrix = confusion_matrix(all_labels, binary_preds)\n\n# Print the results\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision: {test_precision:.4f}\")\nprint(f\"Test Recall: {test_recall:.4f}\")\nprint(f\"Test F1 Score: {test_f1:.4f}\")\nprint(f\"Test AUC-ROC: {test_auc:.4f}\")\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Referral Glaucoma\", \"Referral Glaucoma\"], \n            yticklabels=[\"Non-Referral Glaucoma\", \"Referral Glaucoma\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T15:04:39.175887Z","iopub.execute_input":"2024-11-02T15:04:39.176258Z","iopub.status.idle":"2024-11-02T15:04:57.389901Z","shell.execute_reply.started":"2024-11-02T15:04:39.176221Z","shell.execute_reply":"2024-11-02T15:04:57.388860Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# import torch\n# import torch.nn as nn\n# from torchvision.models import vit_l_16, ViT_L_16_Weights\n# from torch.utils.data import DataLoader\n# import numpy as np\n# from sklearn.metrics import roc_auc_score, roc_curve\n# from tqdm import tqdm\n\n# # from data_utils import GlaucomaDataset, test_transform\n\n# ####### Adjust this section as needed ############################\n# # model_save_directory = './model/ViT_glaucoma_ROI'    \n# # img_folder = './ROI_images' \n# # test_df = pd.read_csv('./Datasets/glaucoma_masks_test.csv')\n\n# # Unmute to validate ViT without ROI\n# model_save_directory = '/kaggle/working/model'  \n# img_folder = '/kaggle/input/preprocessed-image-hda-without-roi/preprocessed_images' \n# test_df = pd.read_csv('/kaggle/input/images-hda-before-preprocess/glaucoma_no_mask_test.csv')\n# #################################################################\n\n# # Load test data\n# test_dataset = GlaucomaDataset(dataframe=test_df, img_folder=img_folder, transform=test_transform)\n# test_loader = DataLoader(test_dataset, batch_size=12, shuffle=True, num_workers=2)\n\n# # Model setup\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# # model = vit_l_16(weights=ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1)\n# weights = ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1                                                                                               \n# model = vit_b_16(weights=weights)\n# model.heads.head = nn.Linear(model.heads.head.in_features, 1)\n# model.to(device)\n\n# def load_model(model, model_path, device):\n#     state_dict = torch.load(model_path, map_location=device)\n#     if any(k.startswith('module.') for k in state_dict.keys()):\n#         new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n#     else:\n#         new_state_dict = state_dict\n#     model.load_state_dict(new_state_dict)\n\n# def compute_metrics(actuals, probabilities):\n#     fpr, tpr, thresholds = roc_curve(actuals, probabilities)\n#     target_specificity = 0.95\n#     target_fpr = 1 - target_specificity\n\n#     # Find the first threshold where FPR is <= target FPR\n#     index = np.where(fpr <= target_fpr)[0][0]\n#     optimal_threshold = thresholds[index]\n#     predictions = (probabilities >= optimal_threshold).astype(int)\n\n#     TP = np.sum((actuals == 1) & (predictions == 1))\n#     TN = np.sum((actuals == 0) & (predictions == 0))\n#     FP = np.sum((actuals == 0) & (predictions == 1))\n#     FN = np.sum((actuals == 1) & (predictions == 0))\n\n#     sensitivity = TP / (TP + FN) if TP + FN > 0 else 0\n#     specificity = TN / (TN + FP) if TN + FP > 0 else 0\n#     accuracy = (TP + TN) / (TP + TN + FP + FN) if TP + TN + FP + FN > 0 else 0\n#     auc = roc_auc_score(actuals, probabilities) if len(np.unique(actuals)) > 1 else 0\n#     return sensitivity, specificity, accuracy, auc, optimal_threshold\n\n# # Evaluate all models in the directory\n# for filename in os.listdir(model_save_directory):\n#     if filename.endswith(\".pth\"):\n#         model_path = os.path.join(model_save_directory, filename)\n#         load_model(model, model_path, device)\n#         model.eval()\n\n#         all_labels = []\n#         all_probabilities = []\n#         with torch.no_grad():\n#             for images, labels in tqdm(test_loader, desc=f\"Evaluating {filename}\", leave=True):\n#                 images = images.to(device)\n#                 outputs = model(images)\n#                 probabilities = torch.sigmoid(outputs).squeeze()\n#                 all_labels.extend(labels.numpy())\n#                 all_probabilities.extend(probabilities.cpu().numpy())\n\n#         sensitivity, specificity, accuracy, auc_score, optimal_threshold = compute_metrics(np.array(all_labels), np.array(all_probabilities))\n#         print(f\"Model: {filename}\")\n#         print(f\"Sensitivity: {sensitivity:.4f}\")\n#         print(f\"Specificity: {specificity:.4f}\")\n#         print(f\"Accuracy: {accuracy:.4f}\")\n#         print(f\"AUC Score: {auc_score:.4f}\")\n#         print(f\"Optimal Threshold: {optimal_threshold:.4f}\\n\")","metadata":{},"outputs":[],"execution_count":null}]}